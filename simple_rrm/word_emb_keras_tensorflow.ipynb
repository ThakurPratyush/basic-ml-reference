{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\thaku\\Downloads\\m23\\ann_class_pro\\annenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences to form embedding \n",
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'i am a good boy',\n",
    "        'i am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'your videos are good']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'i am a good boy',\n",
       " 'i am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define vocab size\n",
    "voc_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[117, 270, 611, 3],\n",
       " [117, 270, 611, 549],\n",
       " [117, 386, 611, 630],\n",
       " [203, 867, 891, 346, 818],\n",
       " [203, 867, 891, 346, 614],\n",
       " [304, 117, 756, 611, 620],\n",
       " [575, 609, 284, 346]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_rep = [one_hot(sentence, voc_size) for sentence in sent]\n",
    "one_hot_rep\n",
    "# one_hot is passed with 2 parameters sentence and vec_size where in ssentece is each line in the list of sentences\n",
    "# this takes each word in a sentence and maps to an index in the vocabulary \n",
    "# since we took vocab size = 1000 so we would map to index 0 -999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we would pass this representation to the embedding layer and get the embeddings \n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0, 117, 270, 611,   3],\n",
       "       [  0,   0,   0,   0, 117, 270, 611, 549],\n",
       "       [  0,   0,   0,   0, 117, 386, 611, 630],\n",
       "       [  0,   0,   0, 203, 867, 891, 346, 818],\n",
       "       [  0,   0,   0, 203, 867, 891, 346, 614],\n",
       "       [  0,   0,   0, 304, 117, 756, 611, 620],\n",
       "       [  0,   0,   0,   0, 575, 609, 284, 346]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## padding each sent to have same number of indexes as representation\n",
    "## making all sent of same length\n",
    "sent_length = 8\n",
    "# we decide that each sent has length of 8 \n",
    "embeded_docs = pad_sequences(one_hot_rep, padding = 'pre', maxlen=sent_length)\n",
    "## allows to add 4 o's on end or start\n",
    "embeded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feture rep \n",
    "dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\thaku\\Downloads\\m23\\ann_class_pro\\annenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\thaku\\Downloads\\m23\\ann_class_pro\\annenv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Embedding(voc_size,dim, input_length = sent_length))\n",
    "model.compile(optimizer = 'adam', loss = \"mse\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 100)            100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 117, 270, 611,   3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = embeded_docs[0]\n",
    "sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size is 10,000 so this would be features also\n",
    "model.predict(sample_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every sent in the sentence list is converted into 1000 dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
